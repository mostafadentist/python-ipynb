{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of covid_19_xray_prediction_using_arcface_with_Catalyst.ipynb","provenance":[{"file_id":"1sXoOH_gG6V7J90FlzUMmwyC51KahtVF3","timestamp":1586467637269}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zWSVF9Lklt_h","colab_type":"code","outputId":"f66ca5f0-760c-40ee-dfe6-754696bd24d1","executionInfo":{"status":"ok","timestamp":1586467869930,"user_tz":-120,"elapsed":21316,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! pip install -U catalyst tensorflow albumentations timm git+git://github.com/mlmed/torchxrayvision.git#egg=torchxrayvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting catalyst\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/cb/10860c15a9226728f14a5243e99e8399c6a5735b29f465bc91f3a2a29d34/catalyst-20.4.1-py2.py3-none-any.whl (326kB)\n","\r\u001b[K     |█                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 33.2MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 33.6MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 61kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 71kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 81kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 163kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 174kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 184kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 194kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 204kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 215kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 327kB 12.5MB/s \n","\u001b[?25hRequirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n","Collecting albumentations\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/40/a343ecacc7e22fe52ab9a16b84dc6165ba05ee17e3729adeb3e2ffa2b37b/albumentations-0.4.5.tar.gz (116kB)\n","\u001b[K     |████████████████████████████████| 122kB 41.1MB/s \n","\u001b[?25hCollecting timm\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/26/ba294669cc5cc4d09efd1964c8df752dc0955ac26f86bdeec582aed77d1d/timm-0.1.20-py3-none-any.whl (161kB)\n","\u001b[K     |████████████████████████████████| 163kB 51.7MB/s \n","\u001b[?25hCollecting torchxrayvision\n","  Cloning git://github.com/mlmed/torchxrayvision.git to /tmp/pip-install-rzu2o420/torchxrayvision\n","  Running command git clone -q git://github.com/mlmed/torchxrayvision.git /tmp/pip-install-rzu2o420/torchxrayvision\n","Requirement already satisfied, skipping upgrade: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.38.0)\n","Requirement already satisfied, skipping upgrade: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.2.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.18.2)\n","Requirement already satisfied, skipping upgrade: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.16.2)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (20.3)\n","Requirement already satisfied, skipping upgrade: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.4.0)\n","Requirement already satisfied, skipping upgrade: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.5.0)\n","Requirement already satisfied, skipping upgrade: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n","Requirement already satisfied, skipping upgrade: imageio in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.4.1)\n","Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.1.2.30)\n","Collecting deprecation\n","  Downloading https://files.pythonhosted.org/packages/b9/2a/d5084a8781398cea745c01237b95d9762c382697c63760a95cc6a814ad3a/deprecation-2.0.7-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.1)\n","Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.10.0)\n","Collecting Pillow<7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 54.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.0.3)\n","Collecting GitPython>=2.1.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 51.9MB/s \n","\u001b[?25hCollecting crc32c>=1.7\n","  Downloading https://files.pythonhosted.org/packages/ab/82/f60248c01a8a23ae07bd4c43d78d69b20ffe324311db3b0785e391aa09d2/crc32c-2.0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n","Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 63.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Collecting imgaug<0.2.7,>=0.2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n","\u001b[K     |████████████████████████████████| 634kB 56.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.6.0.post2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (2.21.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (46.1.3)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.2.1)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.7.2)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst) (2.4)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst) (1.1.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->catalyst) (2.4.6)\n","Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.2)\n","Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n","Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.1.3)\n","Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n","Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n","Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n","Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.14.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (2.8.1)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.2.0)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f5/8f84b3bf9d94bdf2454a302f2fa375832b53660ea532586b8a55ff16ae9a/gitdb-4.0.2-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2.8)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (3.1.1)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.1.9)\n","Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n","Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/35/d2/27777ab463cd44842c78305fa8097dfba0d94768abbb7e1c4d88f1fa1a0b/smmap-3.0.1-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n","Building wheels for collected packages: albumentations, torchxrayvision, imgaug\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=64378 sha256=973cc9e0461e53d2cd5b9c2ca4a6593a0dc20338deba49516886f529d83726b1\n","  Stored in directory: /root/.cache/pip/wheels/f0/a0/61/e50f93165a5ec7e7f5d65064e513239505bc4c06d2289557d3\n","  Building wheel for torchxrayvision (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchxrayvision: filename=torchxrayvision-0.0.3-cp36-none-any.whl size=16483 sha256=4d6d67fa019b3802e8ce1e3c239bbc0636fec2afbe9dc512ea6a5b54f54e8065\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4mmkpgky/wheels/a6/85/4b/fe7ddcb97afdb30bff1045e9ab4e02d47899d223a50e93c0e0\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=c1234b54d00b74001386936ad529c3dcffb219d4b10cb4b05a56b3087f83a9da\n","  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n","Successfully built albumentations torchxrayvision imgaug\n","Installing collected packages: deprecation, Pillow, smmap, gitdb, GitPython, crc32c, tensorboardX, catalyst, imgaug, albumentations, timm, torchxrayvision\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed GitPython-3.1.0 Pillow-6.2.2 albumentations-0.4.5 catalyst-20.4.1 crc32c-2.0 deprecation-2.0.7 gitdb-4.0.2 imgaug-0.2.6 smmap-3.0.1 tensorboardX-2.0 timm-0.1.20 torchxrayvision-0.0.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"_BWzcU3eo_9J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"outputId":"ef43cf18-cec8-45dd-cfc3-180edaf647fd","executionInfo":{"status":"error","timestamp":1586467873094,"user_tz":-120,"elapsed":24430,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}}},"source":["import os\n","import sys\n","import random\n","import subprocess\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","\n","import torchxrayvision as xrv"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-91d086aa2d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchxrayvision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msvhn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVHN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mphototour\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhotoTour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfakedata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFakeData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msemeion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSEMEION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0momniglot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmniglot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/fakedata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPILLOW_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0maccimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misStringType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'isStringType'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"ii0Oaslsti9N","colab_type":"text"},"source":["## Data from [Covid-19 chestxray dataset](https://github.com/ieee8023/covid-chestxray-dataset)"]},{"cell_type":"markdown","metadata":{"id":"bTA-7CM05VWc","colab_type":"text"},"source":["With repo updates, you can rerun this notebook to gather better results."]},{"cell_type":"code","metadata":{"id":"MTbTBFq-mIwj","colab_type":"code","colab":{}},"source":["def run_cmd(cmd, stderr=subprocess.STDOUT):\n","  out = None\n","  try:\n","    out = subprocess.check_output(\n","      [cmd], \n","      shell=True,\n","      stderr=subprocess.STDOUT, \n","      universal_newlines=True,\n","    )\n","  except subprocess.CalledProcessError as e:\n","    print(f'ERROR {e.returncode}: {cmd}\\n\\t{e.output}', flush=True, file=sys.stderr)\n","    raise e\n","  return out\n","\n","def clone_data(data_root):\n","  clone_uri = 'https://github.com/ieee8023/covid-chestxray-dataset.git'\n","  if os.path.exists(data_root):\n","      assert os.path.isdir(data_root), \\\n","        f'{data_root} should be cloned from {clone_uri}'\n","  else:\n","      print(\n","        'Cloning the covid chestxray dataset. It may take a while\\n...\\n', \n","        flush=True\n","        )\n","      run_cmd(f'git clone {clone_uri} {data_root}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WuJkr4f_mmAl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"08392053-bfc2-4626-90af-adfd8e13c962","executionInfo":{"status":"ok","timestamp":1586467940880,"user_tz":-120,"elapsed":19817,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}}},"source":["data_root = \"./data\"\n","clone_data(data_root)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Cloning the covid chestxray dataset. It may take a while\n","...\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3bcVW_7lm42_","colab_type":"code","outputId":"d1252455-4dfd-4bf1-a2f7-01b23877cd83","executionInfo":{"status":"error","timestamp":1586468219928,"user_tz":-120,"elapsed":3372,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}},"colab":{"base_uri":"https://localhost:8080/","height":452}},"source":["from catalyst.dl import utils\n","\n","dataset = xrv.datasets.COVID19_Dataset(\n","    imgpath=f'{data_root}/images',\n","    csvpath=f'{data_root}/metadata.csv',\n","    transform=None,\n",")\n","print(f'Covid Chest x-ray stats dataset stats:\\n{dataset}\\n\\n', flush=True)\n","\n","n_train = int(0.8 * len(dataset))\n","n_valid = len(dataset) - n_train\n","\n","utils.set_global_seed(42)\n","train_data, valid_data = torch.utils.data.random_split(\n","    dataset, [n_train, n_valid])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n","\n","numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n","\n","numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n","\n","numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","\n","alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-28360821cd5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcatalyst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dataset = xrv.datasets.COVID19_Dataset(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimgpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{data_root}/images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcsvpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{data_root}/metadata.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'xrv' is not defined"]}]},{"cell_type":"code","metadata":{"id":"NX_-g3pvp_cY","colab_type":"code","outputId":"90828241-9dbd-4aef-d6fd-d084fb7c7c0a","executionInfo":{"status":"error","timestamp":1586468263622,"user_tz":-120,"elapsed":1775,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["train_data[0], train_data[0]['PA'].shape, train_data[0]['lab'].shape, \\\n","  len(train_data), len(valid_data)"],"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-472d1365f0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"EEl7Sbjr5JMR","colab_type":"text"},"source":["### Augmentations with [Albumentations](https://github.com/albumentations-team/albumentations)"]},{"cell_type":"code","metadata":{"id":"mrExXZTS2yBK","colab_type":"code","colab":{}},"source":["from catalyst.data import Augmentor\n","import albumentations as albu\n","from albumentations.pytorch import ToTensor\n","\n","BORDER_CONSTANT = 0\n","BORDER_REFLECT = 2\n","crop_size = 224\n","scale_size = crop_size * 4\n","\n","\n","train_transforms = albu.Compose([\n","  albu.LongestMaxSize(max_size=scale_size),\n","  albu.PadIfNeeded(scale_size, scale_size, border_mode=BORDER_CONSTANT),\n","  albu.RandomCrop(crop_size, crop_size),\n","  albu.OneOf([\n","    # Random shifts, stretches and turns with a 50% probability\n","    albu.ShiftScaleRotate( \n","      shift_limit=0.1,\n","      scale_limit=0.1,\n","      rotate_limit=15,\n","      border_mode=BORDER_REFLECT,\n","      p=0.5\n","    ),\n","    albu.Flip(p=0.5),\n","    albu.RandomRotate90(p=0.5),     \n","  ]),\n","  albu.IAAPerspective(scale=(0.02, 0.05), p=0.3),\n","  albu.JpegCompression(quality_lower=80),\n","  ToTensor()\n","])\n","\n","valid_transforms = albu.Compose([\n","  albu.LongestMaxSize(max_size=scale_size),\n","  albu.PadIfNeeded(scale_size, scale_size, border_mode=BORDER_CONSTANT),\n","  albu.CenterCrop(crop_size, crop_size),\n","  ToTensor()\n","])\n","\n","\n","# Takes an image from the input dictionary by the key `dict_key` \n","# and performs `train_transforms` on it.\n","train_transforms_fn = Augmentor(\n","    dict_key=\"PA\",\n","    # due to dataset sctucture from https://github.com/ieee8023/covid-chestxray-dataset\n","    # we need some indices tricks\n","    augment_fn=lambda x: train_transforms(image=x[0][:, :, None])[\"image\"]\n",")\n","\n","\n","# Similarly for the validation part of the dataset. \n","# we only perform scaling and center crop\n","valid_transforms_fn = Augmentor(\n","    dict_key=\"PA\",\n","    augment_fn=lambda x: valid_transforms(image=x[0][:, :, None])[\"image\"]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbhuypF15LYV","colab_type":"text"},"source":["### PyTorch Loaders"]},{"cell_type":"code","metadata":{"id":"Po3Xh4p7n6nR","colab_type":"code","colab":{}},"source":["batch_size = 8\n","num_workers = 4\n","train_data = list(train_data)\n","valid_data = list(valid_data)\n","\n","train_loader = utils.get_loader(\n","  train_data,\n","  open_fn=lambda x: x,\n","  dict_transform=train_transforms_fn,\n","  batch_size=batch_size,\n","  num_workers=num_workers,\n","  shuffle=True,\n","  drop_last=True,\n",")\n","\n","valid_loader = utils.get_loader(\n","  valid_data,\n","  open_fn=lambda x: x,\n","  dict_transform=valid_transforms_fn,\n","  batch_size=batch_size,\n","  num_workers=num_workers,\n","  shuffle=False, \n","  drop_last=True,\n",")\n","\n","# based on https://github.com/ieee8023/covid-chestxray-dataset#view-current-images-and-metadata\n","class_names = [\n","    'ARDS', \n","    'Bacterial Pneumonia', \n","    'COVID-19', \n","    'MERS', \n","    'No Finding', \n","    'Pneumonia', \n","    'SARS', \n","    'Streptococcus', \n","    'Viral Pneumonia'\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gomVcuKP5OT5","colab_type":"text"},"source":["## Monitoring with Tensorboard"]},{"cell_type":"code","metadata":{"id":"s-ICMucHt14a","colab_type":"code","colab":{}},"source":["! pkill -9 tensorboard\n","! rm -rf ./logs\n","%load_ext tensorboard\n","%reload_ext tensorboard\n","%tensorboard --logdir ./logs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OHjor9yt5Pgi","colab_type":"text"},"source":["## Training with [Catalyst](https://github.com/catalyst-team/catalyst)"]},{"cell_type":"code","metadata":{"id":"8Vuuv18d_C-F","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.simplefilter(\"ignore\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"29XlPenIdPcb","colab_type":"text"},"source":["## Metric learning models and Loss function"]},{"cell_type":"code","metadata":{"id":"YWdGP0sQdOrQ","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","from timm import create_model\n","\n","\n","class DenseCrossEntropy(nn.Module):\n","    def forward(self, x, target):\n","        x = x.float()\n","        target = target.float()\n","        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n","\n","        loss = -logprobs * target\n","        loss = loss.sum(-1)\n","        return loss.mean()\n","\n","\n","class ArcFaceLoss(nn.modules.Module):\n","    def __init__(self, s=30.0, m=0.5):\n","        super().__init__()\n","        self.crit = DenseCrossEntropy()\n","        self.s = s\n","        self.cos_m = math.cos(m)\n","        self.sin_m = math.sin(m)\n","        self.th = math.cos(math.pi - m)\n","        self.mm = math.sin(math.pi - m) * m\n","\n","    def forward(self, logits, labels):\n","        logits = logits.float()\n","        cosine = logits\n","        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n","\n","        output = (labels * phi) + ((1.0 - labels) * cosine)\n","        output *= self.s\n","        loss = self.crit(output, labels)\n","        return loss / 2\n","\n","\n","class ArcMarginProduct(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / math.sqrt(self.weight.size(1))\n","        self.weight.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, features):\n","        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n","        return cosine\n","\n","\n","class TIMMetricLearningMModels(nn.Module):\n","    def __init__(self, model_name, num_classes):\n","        super(TIMMetricLearningMModels, self).__init__()\n","        self.model = create_model(\n","            model_name=model_name,\n","            pretrained=True,\n","            num_classes=num_classes,\n","            in_chans=3,\n","        )\n","\n","        features_num = self.model.num_features\n","        embedding_size = 512\n","\n","        self.neck = nn.Sequential(\n","            nn.BatchNorm1d(features_num),\n","            nn.Linear(features_num, embedding_size, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.BatchNorm1d(embedding_size),\n","            # nn.Linear(embedding_size, embedding_size, bias=False),\n","            # nn.BatchNorm1d(embedding_size),\n","        )\n","        self.arc_margin_product = ArcMarginProduct(embedding_size, num_classes)\n","        self.arc_loss = ArcFaceLoss()\n","        self.head = nn.Linear(embedding_size, num_classes)\n","\n","    def freeze(self):\n","        for param in self.model.parameters():\n","            param.requires_grad = False\n","\n","    def unfreeze(self):\n","        for param in self.model.parameters():\n","            param.requires_grad = True\n","\n","    def embed(self, x):\n","        x = self.model.forward_features(x)\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        x = x.view(x.size(0), -1)\n","        embedding = self.neck(x)\n","        return embedding\n","\n","    def metric_classify(self, embedding):\n","        return self.arc_margin_product(embedding)\n","\n","    def classify(self, embedding):\n","        return self.head(embedding)\n","\n","    def forward(self, x):\n","        x = x.repeat(1,3,1,1)\n","        embedding = self.embed(x)\n","        logits = self.classify(embedding)\n","        logits_ml = self.metric_classify(embedding)\n","        return logits, logits_ml, self.arc_loss\n","\n","class MetricLearningLoss(nn.Module):\n","    \"\"\"\n","    NLL loss with label smoothing.\n","    \"\"\"\n","    def __init__(self, ratio=0.5):\n","        \"\"\"\n","        Constructor for the LabelSmoothing module.\n","        :param smoothing: label smoothing factor\n","        \"\"\"\n","        super(MetricLearningLoss, self).__init__()\n","        self.ratio = ratio\n","        self.classification_loss_fn = FocalLossBinary()\n","\n","    def forward(self, logits, logits_ml, loss_fn, lab):\n","        ohe = lab\n","        classification_loss = self.classification_loss_fn(logits, lab)\n","        arcface_loss = loss_fn(logits_ml, ohe)\n","        return self.ratio * classification_loss + (1 - self.ratio) * arcface_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ky5e9ba3ejnA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S13O5zc2ekmM","colab_type":"text"},"source":["## Normal transfer learning model"]},{"cell_type":"code","metadata":{"id":"9CZ_1Oc9ecoM","colab_type":"code","colab":{}},"source":["class TIMMModels(nn.Module):\n","    def __init__(self, model_name, num_classes):\n","        super(TIMMModels, self).__init__()\n","        self.model = create_model(\n","            model_name=model_name,\n","            pretrained=True,\n","            num_classes=num_classes,\n","            in_chans=3,\n","        )\n","\n","    def freeze(self):\n","        for param in self.model.parameters():\n","            param.requires_grad = False\n","\n","    def unfreeze(self):\n","        for param in self.model.parameters():\n","            param.requires_grad = True\n","\n","    def forward(self, x):\n","        x = x.repeat(1,3,1,1)\n","        return self.model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXhm44pFpoji","colab_type":"code","colab":{}},"source":["import torch\n","from catalyst.dl import SupervisedRunner, CriterionCallback, AUCCallback\n","from catalyst.contrib.nn import FocalLossBinary\n","\n","# experiment setup\n","logdir = \"./logs\"\n","num_epochs = 20\n","num_classes = 9\n","\n","# data\n","loaders = {\"train\": train_loader, \"valid\": valid_loader}\n","\n","# model, criterion, optimizer, scheduler\n","model = TIMMetricLearningMModels(model_name=\"resnet34\", num_classes=num_classes)\n","criterion = MetricLearningLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8, 16], gamma=0.3)\n","\n","# model runner\n","runner = SupervisedRunner(\n","  input_key = \"PA\",\n","  output_key = [\"logits\", \"logits_ml\", \"loss_fn\"],\n","  input_target_key = [\"lab\"],\n",")\n","\n","# model training\n","runner.train(\n","    model=model,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scheduler=scheduler,\n","    loaders=loaders,\n","    logdir=logdir,\n","    num_epochs=num_epochs,\n","    verbose=False,\n","    callbacks=[\n","        CriterionCallback(\n","            input_key=[\"lab\"],\n","            output_key=[\"logits\", \"logits_ml\", \"loss_fn\"],\n","        ),\n","        AUCCallback(\n","            input_key=\"lab\",\n","            output_key=\"logits\",\n","            prefix=\"auc\",\n","            num_classes=num_classes,\n","            class_names=class_names,\n","        )\n","    ],\n","    # let's maximaze AUC for COVID-19 prediction\n","    main_metric=\"auc/class_COVID-19\",\n","    # AUC needs to be maximized.\n","    minimize_metric=False,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rKRh_3KzzKJU","colab_type":"code","colab":{}},"source":["import torch\n","from catalyst.dl import SupervisedRunner, CriterionCallback, AUCCallback\n","from catalyst.contrib.nn import FocalLossBinary\n","\n","# experiment setup\n","logdir = \"./logs_normal/\"\n","num_epochs = 20\n","num_classes = 9\n","\n","# data\n","loaders = {\"train\": train_loader, \"valid\": valid_loader}\n","\n","# model, criterion, optimizer, scheduler\n","# model = xrv.models.DenseNet(num_classes=num_classes)\n","model = TIMMModels(model_name=\"resnet34\", num_classes=num_classes)\n","criterion = FocalLossBinary()\n","optimizer = torch.optim.Adam(model.parameters())\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8, 16], gamma=0.3)\n","\n","# model runner\n","runner = SupervisedRunner(\n","  input_key = \"PA\",\n","  output_key = \"logits\",\n","  input_target_key = \"lab\",\n",")\n","\n","# model training\n","runner.train(\n","    model=model,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scheduler=scheduler,\n","    loaders=loaders,\n","    logdir=logdir,\n","    num_epochs=num_epochs,\n","    verbose=False,\n","    callbacks=[\n","        CriterionCallback(\n","            input_key=\"lab\",\n","            output_key=\"logits\",\n","        ),\n","        AUCCallback(\n","            input_key=\"lab\",\n","            output_key=\"logits\",\n","            prefix=\"auc\",\n","            num_classes=num_classes,\n","            class_names=class_names,\n","        )\n","    ],\n","    # let's maximaze AUC for COVID-19 prediction\n","    main_metric=\"auc/class_COVID-19\",\n","    # AUC needs to be maximized.\n","    minimize_metric=False,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ix3bXX7xfTuD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"5433ed87-f167-4574-ad3f-20c9640ee576","executionInfo":{"status":"ok","timestamp":1586468463907,"user_tz":-120,"elapsed":3597,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}}},"source":["#mostafa samy\n","# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import cv2\n","import os"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n","\n","numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n","\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n","\n","can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mQRFM1-P5D3M","colab_type":"code","colab":{}},"source":["dataset = \"/content/data/images\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xuESr6Gg5h2A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ca31d481-4a9f-4b0f-e4d1-b3ac4598301e","executionInfo":{"status":"ok","timestamp":1586468634808,"user_tz":-120,"elapsed":1731,"user":{"displayName":"mostafa dentist","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}}},"source":["dataset"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/data/images'"]},"metadata":{"tags":[]},"execution_count":9}]}]}