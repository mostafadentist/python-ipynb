{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"teachable machien.ipynb","provenance":[],"mount_file_id":"1V_7fBDvfnxnlQEcx5V27mLYM85axP9pK","authorship_tag":"ABX9TyPErjhunl909WmeB8KuurpU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1DNowUPp9Co","executionInfo":{"status":"ok","timestamp":1625170691953,"user_tz":-120,"elapsed":19139,"user":{"displayName":"Mostafa Samy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}},"outputId":"a749b30d-ca3d-4731-e458-0f837d8e9a75"},"source":["!unzip /content/converted_keras.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  /content/converted_keras.zip\n","replace keras_model.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pIMVEeWpRva","executionInfo":{"status":"ok","timestamp":1625170735510,"user_tz":-120,"elapsed":3514,"user":{"displayName":"Mostafa Samy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvkMox1t-U4ZLBRkUX3FXwlsU2kT4DNxxO5T-3Q=s64","userId":"03690075681565703598"}},"outputId":"f22b6574-fd8a-4f1e-a0a7-89679bdd0fd4"},"source":["import tensorflow.keras\n","from PIL import Image, ImageOps\n","import numpy as np\n"," \n","# Disable scientific notation for clarity\n"," \n","# Load the model\n","model = tensorflow.keras.models.load_model('keras_model.h5')\n"," \n","# Create the array of the right shape to feed into the keras model\n","# The 'length' or number of images you can put into the array is\n","# determined by the first position in the shape tuple, in this case 1.\n","data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n"," \n","# Replace this with the path to your image\n","image = Image.open('/content/drive/MyDrive/DSC_0455.JPG')\n"," \n","#resize the image to a 224x224 with the same strategy as in TM2:\n","#resizing the image to be at least 224x224 and then cropping from the center\n","size = (224, 224)\n","image = ImageOps.fit(image, size, Image.ANTIALIAS)\n"," \n","#turn the image into a numpy array\n","image_array = np.asarray(image)\n"," \n","# display the resized image\n","image.show()\n"," \n","# Normalize the image\n","normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n"," \n","# Load the image into the array\n","data[0] = normalized_image_array\n"," \n","# run the inference\n","prediction = model.predict(data)\n","print(prediction)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","[[0.06407308 0.9359269 ]]\n"],"name":"stdout"}]}]}